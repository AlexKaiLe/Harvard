{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import progressbar\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, MaxPool2D, LeakyReLU"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "joint_name = ['HeadF', 'HeadB', 'HeadL', 'SpineF', 'SpineM', 'SpineL', \n",
    "            'Offset1', 'Offset2', 'HipL', 'HipR', 'ElbowL', 'ArmL', \n",
    "            'ShoulderL', 'ShoulderR', 'ElbowR', 'ArmR', 'KneeR', \n",
    "            'KneeL', 'ShinL', 'ShinR']\n",
    "\n",
    "joints_idx = [[1, 2], [2, 3], [1, 3], [2, 4], [1, 4], [3, 4], [4, 5], \n",
    "            [5, 6], [4, 7], [7, 8], [5, 8], [5, 7], [6, 8], [6, 9], \n",
    "            [6, 10], [11, 12], [4, 13], [4, 14], [11, 13], [12, 13], \n",
    "            [14, 15], [14, 16], [15, 16], [9, 18], [10, 17], [18, 19], \n",
    "            [17, 20]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Loading mat file and returning file\n",
    "def loadMatFile(fileName, key):\n",
    "    mat = loadmat(fileName)[key]\n",
    "    print(\"Loaded:\",fileName, key)\n",
    "    return mat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Plot 3D points given file and frame number\n",
    "def plotKnownOrder(matFile, numb):\n",
    "    mat = matFile[numb]\n",
    "    x = mat[0]\n",
    "    y = mat[1]\n",
    "    z = mat[2]\n",
    "\n",
    "    # loading plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "    # adding points, labels and lines\n",
    "    try:\n",
    "        ax.scatter(x,y,z, color='#ff5e5e', s =10, marker='x')\n",
    "    except:\n",
    "        pass\n",
    "    # addLabels(ax, x, y, z)\n",
    "    drawLines(ax, x, y, z)\n",
    "    drawAllLines(ax, x, y, z)\n",
    "\n",
    "    # Labeling plot\n",
    "    ax.set_title(\"Rat positioning\")\n",
    "    ax.set_xlabel(\"X axis\")\n",
    "    ax.set_ylabel(\"Y axis\")\n",
    "    ax.set_zlabel(\"Z axis\")\n",
    "    plt.show()\n",
    "\n",
    "# Draw major lines in the rat model\n",
    "def drawLines(ax,x, y, z):\n",
    "    # run through all the connections to draw the points\n",
    "    for i in range(len(joints_idx)):\n",
    "        try: \n",
    "            # Getting both points to draw line\n",
    "            idx = joints_idx[i]\n",
    "            x_line = [x[idx[0]-1], x[idx[1]-1]]\n",
    "            y_line = [y[idx[0]-1], y[idx[1]-1]]\n",
    "            z_line = [z[idx[0]-1], z[idx[1]-1]]\n",
    "            z_coord_1 = x[idx[0]-1], y[idx[0]-1], z[idx[0]-1]\n",
    "            z_coord_2 = x[idx[1]-1], y[idx[1]-1], z[idx[1]-1]\n",
    "\n",
    "            # Draw lines\n",
    "            if i < 3: \n",
    "                ax.plot(x_line, y_line, z_line, c=\"#064ea1\", linewidth=4)\n",
    "            elif i < 6:\n",
    "                ax.plot(x_line, y_line, z_line, c=\"#64ccd1\", linewidth=4)\n",
    "            else:\n",
    "                ax.plot(x_line, y_line, z_line, c=\"#46b8a7\", linewidth=4)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Draw all line from every point \n",
    "def drawAllLines(ax,x, y, z):\n",
    "    joint_len = len(joint_name)\n",
    "    all_lines = []\n",
    "    for i in range(joint_len):\n",
    "        for j in range(joint_len):\n",
    "            if (not([i,j] in all_lines)):\n",
    "                x_line = [x[i], x[j]]\n",
    "                y_line = [y[i], y[j]]\n",
    "                z_line = [z[i], z[j]]\n",
    "                ax.plot(x_line, y_line, z_line, color='#b1d8fc', linewidth=0.5)\n",
    "                all_lines.append([i,j])\n",
    "                all_lines.append([j,i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# normalizes a matrix\n",
    "def normalize(matrix):\n",
    "    max_numb = max(matrix[~np.isnan(matrix)])\n",
    "    norm = matrix/max_numb\n",
    "    return np.array(norm)\n",
    "    # return matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "# Get the distance to every single point \n",
    "def getAllDistances(matFile, numb):\n",
    "    mat = matFile[numb]\n",
    "    mat = mat.T\n",
    "    dist = cdist(mat, mat, 'euclidean')\n",
    "    return normalize(dist)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Get the absolute height difference to every single point \n",
    "def getAllHeights(matFile, numb):\n",
    "    mat = matFile[numb]\n",
    "    z = mat[2]\n",
    "    reshaped = int(matFile.shape[2])\n",
    "    height = []\n",
    "\n",
    "    for i in range(reshaped):\n",
    "        for j in range(reshaped):\n",
    "            if np.nan in [z[i], z[j]]:\n",
    "                height.append(np.nan)\n",
    "            else:\n",
    "                height.append(np.abs(z[i]-z[j]))\n",
    "\n",
    "    # normalizes height data\n",
    "    height = normalize(np.array(height).reshape(reshaped, reshaped))\n",
    "    return height\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Get the angle to every single point \n",
    "def getAllAngles(matFile, numb):\n",
    "    mat = matFile[numb]\n",
    "    mat = mat.T\n",
    "    angle = cdist(mat, mat, 'cosine')\n",
    "    return normalize(angle)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def addNans(raw):\n",
    "    raw_copy = np.array(raw.copy())\n",
    "\n",
    "    for i in range(raw_copy.shape[0]):\n",
    "        rand_numb = np.random.randint(0, 4)\n",
    "        rand_index = random.sample(range(3, 20), rand_numb)\n",
    "        for j in range(rand_numb):\n",
    "            raw_copy[i][:,rand_index[j]] = np.nan\n",
    "    return raw_copy\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def getData(data, numb): \n",
    "    cnn_inputs = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "\n",
    "    for i in bar(range(numb)):\n",
    "        dist = getAllDistances(data, i) \n",
    "        height = getAllHeights(data, i)\n",
    "        angle = getAllAngles(data, i)\n",
    "        for j in range(0, data.shape[2]):\n",
    "            temp = np.array([dist[j], height[j], angle[j]])\n",
    "            first = temp[:,0:3]\n",
    "            second = temp[:,3:20]\n",
    "            first = first [ :, first[0].argsort()]\n",
    "            second = second [ :, second[0].argsort()]\n",
    "            output = np.concatenate((first, second), axis =1)\n",
    "            cnn_inputs.append(output)\n",
    "\n",
    "    # DIMENTION CHANGE\n",
    "    cnn_inputs = np.array(cnn_inputs)[:,:,:13]\n",
    "    # cnn_inputs = np.array(cnn_inputs)[:,:,:20]\n",
    "    cnn_inputs = np.array(cnn_inputs).reshape((cnn_inputs.shape[0], 39))\n",
    "    # cnn_inputs = np.array(cnn_inputs).reshape((numb*data.shape[2], 60))\n",
    "    where_are_NaNs = np.isnan(cnn_inputs)\n",
    "    cnn_inputs[where_are_NaNs] = 0\n",
    "    return cnn_inputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def oneFileTestTrain():\n",
    "    mat_file = loadmat('mat_files/markerSplit_1_shuffled.mat')\n",
    "    data = mat_file['alteredM']\n",
    "    labels = mat_file['labelsM']\n",
    "\n",
    "    # set numb of data used\n",
    "    numb_train = 2000\n",
    "    numb_test = 2000\n",
    "\n",
    "    # find length of data\n",
    "    mat_len = int(len(labels))\n",
    "    mat_half = int(mat_len/2)\n",
    "\n",
    "    # Take some frames from the list to use as trian and test data\n",
    "    index_train = np.linspace(0, mat_half, num = numb_train, endpoint=False).astype(int)\n",
    "    index_test = np.linspace(mat_half, mat_len, num = numb_test, endpoint=False).astype(int)\n",
    "    pre_train_data = data[index_train]\n",
    "    pre_train_labels = labels[index_train]\n",
    "    pre_test_data = data[index_test]\n",
    "    pre_test_labels = labels[index_test]\n",
    "\n",
    "    print(\"Shape of pre_train_data:\", pre_train_data.shape)\n",
    "    print(\"Shape of pre_test_data:\", pre_test_data.shape)\n",
    "    print(\"Shape of pre_train_labels:\", pre_train_labels.shape)\n",
    "    print(\"Shape of pre_test_labels:\", pre_test_labels.shape)\n",
    "    return pre_train_data, pre_test_data, pre_train_labels, pre_test_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "train_file = loadmat('mat_files/bigSet1.mat')\n",
    "test_file = loadmat('mat_files/bigSet2.mat')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_data = train_file['bigSet1']\n",
    "test_data = test_file['bigSet2']\n",
    "train_labels = train_file['labels1']\n",
    "test_labels = test_file['labels2']\n",
    "# set numb of data used\n",
    "numb_train = len(train_data)\n",
    "numb_test = 1000\n",
    "\n",
    "# Take some frames from the list to use as trian and test data\n",
    "index_train = np.linspace(0, len(train_labels), num = numb_train, endpoint=False).astype(int)\n",
    "index_test = np.linspace(0, len(test_labels), num = numb_test, endpoint=False).astype(int)\n",
    "# pre_train_data = train_data[index_train]\n",
    "# pre_train_labels = train_labels[index_train]\n",
    "pre_train_data = train_data\n",
    "pre_train_labels = train_labels\n",
    "pre_test_data = test_data[index_test]\n",
    "pre_test_labels = test_labels[index_test]\n",
    "\n",
    "print(\"Shape of pre_train_data:\", pre_train_data.shape)\n",
    "print(\"Shape of pre_test_data:\", pre_test_data.shape)\n",
    "print(\"Shape of pre_train_labels:\", pre_train_labels.shape)\n",
    "print(\"Shape of pre_test_labels:\", pre_test_labels.shape)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of pre_train_data: (221147, 3, 20)\n",
      "Shape of pre_test_data: (1000, 3, 20)\n",
      "Shape of pre_train_labels: (221147, 20)\n",
      "Shape of pre_test_labels: (1000, 20)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Get measurement data for every 3D point\n",
    "train_data = getData(pre_train_data, numb_train)\n",
    "test_data = getData(pre_test_data, numb_test)\n",
    "\n",
    "# Flatten the trian labels to fit dimentions of data\n",
    "train_labels = pre_train_labels.flatten()[0:(numb_train*20)]-1\n",
    "test_labels = pre_test_labels.flatten()[0:(numb_test*20)]-1\n",
    "\n",
    "print(\"Shape of train_data:\", train_data.shape)\n",
    "print(\"Shape of test_data:\", test_data.shape)\n",
    "print(\"Shape of train_labels:\", train_labels.shape)\n",
    "print(\"Shape of test_labels:\", test_labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100% (221147 of 221147) |################| Elapsed Time: 0:25:19 Time:  0:25:19\n",
      "100% (1000 of 1000) |####################| Elapsed Time: 0:00:05 Time:  0:00:05\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of train_data: (4422940, 39)\n",
      "Shape of test_data: (20000, 39)\n",
      "Shape of train_labels: (4422940,)\n",
      "Shape of test_labels: (20000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Get index where the data is all 0\n",
    "nans_train = np.sort(np.where(~train_data.any(axis=1))[0])[::-1]\n",
    "nans_test = np.sort(np.where(~test_data.any(axis=1))[0])[::-1]\n",
    "\n",
    "# Turn data into lists\n",
    "train_data_new = list(train_data)\n",
    "test_data_new = list(test_data)\n",
    "train_labels_new = list(train_labels)\n",
    "test_labels_new = list(test_labels)\n",
    "\n",
    "bar = progressbar.ProgressBar()\n",
    "# Remove the nan values \n",
    "for i in bar(nans_train):\n",
    "    train_data_new.pop(i)\n",
    "    train_labels_new.pop(i)\n",
    "bar = progressbar.ProgressBar()\n",
    "for i in bar(nans_test):\n",
    "    test_data_new.pop(i)\n",
    "    test_labels_new.pop(i)\n",
    "\n",
    "# Turn data back into array\n",
    "train_data_new = np.array(train_data_new)\n",
    "train_labels_new = np.array(train_labels_new)\n",
    "test_data_new = np.array(test_data_new)\n",
    "test_labels_new = np.array(test_labels_new)\n",
    "\n",
    "print(\"Shape of train_data_new:\", train_data_new.shape)\n",
    "print(\"Shape of test_data_new:\", test_data_new.shape)\n",
    "print(\"Shape of train_labels_new:\", train_labels_new.shape)\n",
    "print(\"Shape of test_labels_new:\", test_labels_new.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 57% (229156 of 397563) |#########       | Elapsed Time: 0:12:25 ETA:   0:22:13"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creates the ML training platform to predict rat joints\n",
    "def ml_traning(train_data, train_labels, test_data, test_labels):\n",
    "    # DIMENTION CHANGE\n",
    "    train_data = train_data.reshape(train_data.shape[0], 39)\n",
    "    test_data = test_data.reshape(test_data.shape[0], 39)\n",
    "    # train_data = train_data.reshape(train_data.shape[0], 60)\n",
    "    # test_data = test_data.reshape(test_data.shape[0], 60)\n",
    "    train_data = train_data.astype('float32')\n",
    "    test_data = test_data.astype('float32')\n",
    "\n",
    "    model = createModel()\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x=train_data,y=train_labels, verbose='auto', batch_size=20, epochs=2)\n",
    "    \n",
    "    output = model.evaluate(test_data, test_labels)\n",
    "    print(\"Loss:\", output[0])\n",
    "    print(\"Accuracy:\", output[1]*100)\n",
    "    return model\n",
    "\n",
    "# Creates the model for the CNN\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(120, activation= LeakyReLU()))\n",
    "    model.add(Dense(320, activation= LeakyReLU()))\n",
    "    # model.add(Dropout(rate=0.25))\n",
    "    model.add(Dense(80, activation= LeakyReLU()))\n",
    "    # model.add(Dense(13, activation = \"softmax\"))\n",
    "    model.add(Dense(len(joint_name), activation = \"softmax\"))\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "skeleton_model = ml_traning(train_data_new, train_labels_new, test_data_new, test_labels_new)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tests individual points and tells you if the CNN worked\n",
    "def handTest(image_index, test_data, label, model, maxNumb):\n",
    "    max_index = len(joint_name)*maxNumb-1\n",
    "    if image_index <= max_index:\n",
    "        predict(test_data, image_index, label, model)\n",
    "    else:\n",
    "        print(\"ERROR: Your predict_index must be below\", max_index)\n",
    "\n",
    "# Showing individual predictions\n",
    "def predict(data, image_index, label, model):\n",
    "    img = [data[image_index]]\n",
    "    # DIMENTION CHANGE\n",
    "    img = np.array(img).reshape(3,13)\n",
    "    # img = np.array(img).reshape(3,20)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    pred = model.predict(img.reshape(1, 39))\n",
    "    # pred = model.predict(img.reshape(1, 60))\n",
    "    predict = pred.argmax()\n",
    "    actual = label[image_index]\n",
    "\n",
    "    print(\"Actual:\", actual)\n",
    "    print(\"Predicted:\", predict)\n",
    "    \n",
    "    if predict == actual:\n",
    "        print(\"YAY ✿(ᵔ‿ᵔ)\")\n",
    "    else:\n",
    "        print(\"Wrong (◕︵◕)\")\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# temp = test_data[0].reshape(3,13)\n",
    "# print(temp)\n",
    "# plt.imshow(temp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for i in range(420,440):\n",
    "#     handTest(i, test_data, test_labels, skeleton_model, numb_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# index = 1234\n",
    "# frame = int(index/20)\n",
    "\n",
    "# print(\"Train input\")\n",
    "# plt.imshow(pre_train_data[frame].reshape(3,20))\n",
    "# plt.show()\n",
    "# # DIMENTION CHANGE\n",
    "# plt.imshow(train_data[index].reshape(3,13))\n",
    "# # plt.imshow(train_data[index].reshape(3,20))\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Test input\")\n",
    "# plt.imshow(pre_test_data[frame].reshape(3,20))\n",
    "# plt.show()\n",
    "# plt.imshow(test_data[index].reshape(3,13))\n",
    "# # plt.imshow(test_data[index].reshape(3,20))\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load file\n",
    "temporal_data = loadmat('mat_files/test_temp.mat')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_pts = temporal_data['new_combed']\n",
    "print(time_pts.shape)\n",
    "\n",
    "num_fms = 3000\n",
    "num_pts = int(time_pts.shape[0]/3)\n",
    "test_pts = time_pts[:,:num_fms]\n",
    "\n",
    "plt.imshow(time_pts, interpolation='nearest', aspect=\"auto\")\n",
    "plt.show()\n",
    "plt.imshow(test_pts, interpolation='nearest', aspect=\"auto\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_pts = test_pts.reshape(num_pts, 3, num_fms).T\n",
    "processed_time = getData(input_pts, num_fms)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_data = time_pts.reshape((len(time_pts), time_pts.shape[1]))\n",
    "select_time = time_data[:3000]\n",
    "input_time = select_time.reshape(select_time.shape[0], 3, int(select_time.shape[1]/3)).astype(float)\n",
    "processed_time = getData(input_time, 3000)\n",
    "print(processed_time.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Shape of inputs:\", input_pts.shape)\n",
    "frame_index = 123\n",
    "pt = 2\n",
    "plt.imshow(input_pts[frame_index].reshape(3,num_pts), interpolation='nearest', aspect=\"auto\")\n",
    "plt.show()\n",
    "\n",
    "process_pts = processed_time.reshape(3000, 22, 39)\n",
    "plt.imshow(process_pts[frame_index], interpolation='nearest', aspect=\"auto\")\n",
    "plt.show()\n",
    "\n",
    "temp = processed_time.reshape(3000, 22, 39)\n",
    "presplit_process = np.transpose(temp,(1, 0, 2))\n",
    "\n",
    "plt.imshow(presplit_process[:,frame_index], interpolation='nearest', aspect=\"auto\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(test_pts.shape)\n",
    "print(input_pts.shape)\n",
    "print(process_pts.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "chunks = []\n",
    "temp = np.ones((22,3000))\n",
    "bar = progressbar.ProgressBar()\n",
    "# run through all the registered points (0,22)\n",
    "for i in (range(num_pts)):\n",
    "    # get every third row\n",
    "    row = i*3\n",
    "    row_list = []\n",
    "    temp_list = []\n",
    "\n",
    "    # # run through length of each row (0,3000)\n",
    "    for j in range(num_fms): \n",
    "        # not a nan, add index to list\n",
    "        if not np.isnan(test_pts[row][j]):\n",
    "            temp_list.append(j)\n",
    "            temp[i][j] +=1 \n",
    "        # if element is a nan and the current list is not empty\n",
    "        elif len(temp_list) > 0:\n",
    "            # add list to output and clear the list\n",
    "            row_list.append([temp_list[0], temp_list[-1]])\n",
    "            temp_list = []\n",
    "    # edge case, add to output if the list still contains values\n",
    "    if len(temp_list) > 0:\n",
    "        row_list.append([temp_list[0], temp_list[-1]])\n",
    "    chunks.append(row_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "ax1.imshow(temp, interpolation='nearest', aspect=\"auto\")\n",
    "ax2.imshow(test_pts[::3], interpolation='nearest', aspect=\"auto\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # Check the chunk list\n",
    "# chunks = np.array(chunks, dtype=list)\n",
    "# # (0,21)\n",
    "# for i in range(len(chunks)):\n",
    "#     print(\"(\"+str(i) +\", \" + str(len(chunks[i])) + \"):\")\n",
    "#     # length of chunk\n",
    "#     for j in range(len(chunks[i])):\n",
    "#         begin = chunks[i][j][0]\n",
    "#         end = chunks[i][j][-1]\n",
    "#         print(\"        \" + str(end-begin+1)+ \" [\"+ str(begin)+ \", \" + str(end) + \"]\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp = processed_time.reshape(3000, 22, 39)\n",
    "presplit_process = np.transpose(temp,(1, 0, 2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(presplit_process.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy import stats\n",
    "temporal_data = []\n",
    "segment_range = []\n",
    "\n",
    "# loop through all the points (0,22)\n",
    "# for i in range(len(chunks)):\n",
    "for i in range(3):\n",
    "    seg_range = []\n",
    "    mode_predict = []\n",
    "    conf_predict = []\n",
    "\n",
    "    # list of chunks in a row\n",
    "    data = chunks[i]\n",
    "    print(\"\\nPoint: (\"+ str(i) + \", \" + str(len(data))+\")\")\n",
    "    \n",
    "    # loop through all the chunks per row (0,1)\n",
    "    for j in range(len(data)):\n",
    "        conf = []\n",
    "        pred = []\n",
    "        seg = data[j] #segment range ie. [0,2999]\n",
    "        lower = seg[0]\n",
    "        upper = seg[-1]\n",
    "        seg_len = upper - lower + 1\n",
    "        seg_range.append(seg)\n",
    "        \n",
    "        # loop through range of each chunk (0,3000)\n",
    "        bar = progressbar.ProgressBar()\n",
    "        # for k in bar(data[j]): \n",
    "        for k in bar(range(10)): \n",
    "            # process_pts[frame num][point num] \n",
    "            # processed_data = process_pts[k][i].reshape(1,39)\n",
    "            processed_data = presplit_process[i][k].reshape(1,39)\n",
    "            # plt.imshow(processed_data.reshape(3,13), interpolation='nearest', aspect=\"auto\")\n",
    "            # plt.show()\n",
    "            model_pred = skeleton_model.predict(processed_data)\n",
    "            \n",
    "            # get the confidence of predicition\n",
    "            if len(conf) == 0: \n",
    "                conf = model_pred[0]\n",
    "            else:\n",
    "                conf += model_pred[0]\n",
    "\n",
    "            # get prediction\n",
    "            pred.append(model_pred.argmax())\n",
    "            \n",
    "        # turn into arrays\n",
    "        conf = np.array(conf)\n",
    "        pred = np.array(pred)\n",
    "        plt.imshow([conf], interpolation='nearest', aspect=\"auto\")\n",
    "        plt.show()\n",
    "\n",
    "        # get mode predictions\n",
    "        mode_data = stats.mode(pred, axis = 0)\n",
    "        mode_pred = mode_data[0].flatten()[0]\n",
    "        mode_count = mode_data[1].flatten()[0]\n",
    "        mode_conf = mode_count/seg_len\n",
    "\n",
    "        # get confidence predictions\n",
    "        conf_pred = conf.argmax()\n",
    "        conf_count = np.sum(pred == conf_pred)\n",
    "        conf_conf = conf.max()/seg_len\n",
    "\n",
    "        mode_predict.append([mode_pred, mode_conf, mode_count, seg_len])\n",
    "        conf_predict.append([conf_pred, conf_conf, conf_count, seg_len])\n",
    "\n",
    "        print(str(i) + \") (\" + str(mode_pred) + \", \" + str(conf_pred) + \") : ([\" + str(mode_count) + \", \" + str(conf_count) + \"] /\", seg_len, \")\", end = \" \")\n",
    "        if (mode_pred == conf_pred):\n",
    "            print(\"Yay\")\n",
    "        else:\n",
    "            print(\"Conflict\")\n",
    "    segment_range.append(sorted(seg_range))\n",
    "    temporal_data.append([mode_predict, conf_predict])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(1):\n",
    "    print(len(segment_range[i]))\n",
    "    print(temporal_data[i][0][0])\n",
    "    print(temporal_data[i][1][0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(4): \n",
    "    print(temporal_data[7][i], \"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_copy = temporal_data.copy()\n",
    "pred_data = np.array(temp_copy, dtype=object)\n",
    "chunk_data = []\n",
    "\n",
    "# print(pred_data[:,1][21])\n",
    "# print(pred_data[:,2][21])\n",
    "# print(pred_data[:,3][21])\n",
    "\n",
    "for i in range(20):\n",
    "    chunk_data.append([])\n",
    "\n",
    "for i in range(22):\n",
    "    index = pred_data[:,1][i]\n",
    "    # pred = pred_data[:,2][i] # mode\n",
    "    pred = pred_data[:,3][i] # certainty \n",
    "    for j in range(len(index)):\n",
    "        if len(index[j]) == 3:\n",
    "            length = index[j][2]-index[j][1] + 1\n",
    "        else:\n",
    "            length = 1\n",
    "        add_data = pred[j] + [length] + index[j]\n",
    "        chunk_data[add_data[0]].append(add_data)\n",
    "\n",
    "for i in range(len(chunk_data)):\n",
    "    print(i, len(chunk_data[i]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(chunk_data[3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prepross = []\n",
    "# for i in range(len(chunk_data)): \n",
    "for i in range(20): \n",
    "    current = chunk_data[i]\n",
    "    sorted_current = sorted(current,key=lambda x: x[4])\n",
    "    numb_index = []\n",
    "    bounds = None\n",
    "    for j in reversed(range(len(sorted_current))):\n",
    "        input_index = sorted_current[j][5:8]\n",
    "        current_bounds = np.arange(input_index[1], input_index[2]+1)\n",
    "        if len(numb_index) == 0:\n",
    "            numb_index.append(input_index)\n",
    "            bounds = current_bounds.tolist()\n",
    "        else:\n",
    "            temp_curent = current_bounds.tolist()\n",
    "            # gets overlapping elements \n",
    "            same = list(set(temp_curent) & set(bounds))\n",
    "\n",
    "            # no overlapp between the two lists\n",
    "            if len(same) == 0:\n",
    "                numb_index.append(input_index)\n",
    "                bounds += temp_curent\n",
    "            else:\n",
    "                if temp_curent[0] in bounds and temp_curent[-1] in bounds:\n",
    "                    # print(\"Can't add index in range [\" + str(temp_curent[0]) + \", \" + str(temp_curent[-1]) + \"] to [\" + str(bounds[0])+ \", \" + str(bounds[-1]) + \"]\")\n",
    "                    break\n",
    "                \n",
    "                # just in case\n",
    "                \n",
    "                # lower bound is inside current bound\n",
    "                if temp_curent[0] in bounds:\n",
    "                    print(\"lower\", temp_curent[0], bounds[-1], temp_curent[0], temp_curent[-1])\n",
    "                    lower = bounds[-1]\n",
    "                    higher = temp_curent[-1]\n",
    "                    new_index = [input_index[0],lower, higher]\n",
    "                    new_bounds = np.arange(lower, higher+1).tolist()\n",
    "\n",
    "                    numb_index.append(new_index)\n",
    "                    bounds += new_bounds\n",
    "                # higher bound is inside current bound\n",
    "                elif temp_curent[-1] in bounds:\n",
    "                    print(\"upper\")\n",
    "                    lower = temp_curent[0]\n",
    "                    higher = bounds[0]\n",
    "                    new_index = [input_index[0],lower, higher]\n",
    "                    new_bounds = np.arange(lower, higher+1).tolist()\n",
    "\n",
    "                    numb_index.append(new_index)\n",
    "                    bounds += new_bounds\n",
    "                    \n",
    "        bounds = sorted(bounds)\n",
    "    new_index = sorted(numb_index,key=lambda x: x[1])\n",
    "    prepross.append([i, new_index, bounds])        \n",
    "    \n",
    "    # print(i, numb_index)\n",
    "    # pic = np.zeros(3001)\n",
    "    # for j in range(len(numb_index)):\n",
    "    #     temp_range = np.arange(numb_index[j][1], numb_index[j][2]+1)\n",
    "    #     for k in temp_range:\n",
    "    #         pic[k] += 1\n",
    "    # plt.imshow([pic], interpolation='nearest', aspect=300)\n",
    "    # plt.show()\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_points = []\n",
    "for i in range(20):\n",
    "    final_points.append([])\n",
    "print(test_time.shape)\n",
    "point_coord = np.ones((60,3000))*np.nan\n",
    "for i in range(len(prepross)):\n",
    "    index = [i*3, i*3+1, i*3+2]\n",
    "    error = False\n",
    "    for j in range(len(prepross[i][1])):\n",
    "        if len(prepross[i][1][j]) != 3:\n",
    "            print(\"error\")\n",
    "\n",
    "        first = prepross[i][1][j][1]\n",
    "        end = prepross[i][1][j][2]\n",
    "        old_index = prepross[i][1][j][0]\n",
    "        old_index_range = [old_index*3, old_index*3+1, old_index*3+2]\n",
    "        print(old_index, old_index_range)\n",
    "        for k in range(first, end+1):\n",
    "            point_coord[index[0]][k] = test_time[old_index_range[0]][k]\n",
    "            point_coord[index[1]][k] = test_time[old_index_range[1]][k]\n",
    "            point_coord[index[2]][k] = test_time[old_index_range[2]][k]\n",
    "            if np.isnan(test_time[old_index_range[0]][k]) or np.isnan(test_time[old_index_range[1]][k]) or np.isnan(test_time[old_index_range[2]][k]):\n",
    "               error = True\n",
    "    if error:\n",
    "        print(i)     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temporal = loadmat('mat_files/newcombed.mat')\n",
    "file_times = temporal['Newcombed']\n",
    "transpose_time = file_times.reshape((len(file_times), 3*file_times.shape[2])).T\n",
    "print(transpose_time.shape)\n",
    "numb_times = 3000\n",
    "test_time = transpose_time[:,:numb_times]\n",
    "plt.imshow(test_time, interpolation='nearest', aspect=\"auto\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "chunks = []\n",
    "bar = progressbar.ProgressBar()\n",
    "for i in bar(range(int(test_time.shape[0]/3))):\n",
    "    row = i*3\n",
    "    row_list = []\n",
    "    temp_list = []\n",
    "    for j in range(test_time.shape[1]):\n",
    "        if ~np.isnan(test_time[i][j]):\n",
    "            temp_list.append(j)\n",
    "        else:\n",
    "            if len(temp_list) > 0:\n",
    "                row_list.append(temp_list)\n",
    "                temp_list = []\n",
    "    if len(temp_list) > 0:\n",
    "        row_list.append(temp_list)\n",
    "    chunks.append([i, row_list])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "time_data = file_times.reshape((len(file_times), 3*file_times.shape[2]))\n",
    "print(time_data.shape())\n",
    "# select_time = time_data[:numb_times]\n",
    "# input_time = select_time.reshape(select_time.shape[0], 3, int(select_time.shape[1]/3)).astype(float)\n",
    "# processed_time = getData(input_time, numb_times)\n",
    "# print(processed_time.shape)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8de543a527d38bc21d309dfa8a60aed366b41867ed03b1c23b526625b89003b8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}